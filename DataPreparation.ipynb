{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages: 303\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import codecs\n",
    "import os\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as dates\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from wekeypedia.wikipedia.page import WikipediaPage as Page\n",
    "\n",
    "basedir = 'listgeometry'\n",
    "\n",
    "file_pagenames = \"%s/pagenames\" % basedir\n",
    "pagenames =  codecs.open(file_pagenames,\"r\", \"utf-8-sig\").readlines()\n",
    "pagenames = list(map(lambda x: x.strip(), pagenames))\n",
    "\n",
    "print 'Number of pages:',len(pagenames) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Basic statistics computation\n",
    "##Data gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages load: 303\n",
      "Number of talk pages load: 298\n"
     ]
    }
   ],
   "source": [
    "def load_pages(listofpages,data_dir):\n",
    "    pages_data = {}\n",
    "    for page in listofpages:\n",
    "        if (os.path.exists('%s/%s.json'%(data_dir,page))):\n",
    "            with open('%s/%s.json'%(data_dir,page)) as data:\n",
    "                pages_data[page] = json.load(data)\n",
    "        else:\n",
    "            data = {}\n",
    "            p = Page()\n",
    "            req = p.fetch_info(page)['query']['pages']\n",
    "            pageid = list(req)[0]\n",
    "            if pageid!='-1':\n",
    "                for x in req[pageid]:\n",
    "                    data[x]=req[pageid][x]\n",
    "                data['revisions']=p.get_revisions_list()\n",
    "                data['links']= p.get_links_title()\n",
    "                pages_data[page]=data\n",
    "                f = open('%s/%s.json'% (data_dir,page),'w')\n",
    "                f.write(json.dumps(data))\n",
    "                f.close()\n",
    "    return(pages_data)\n",
    "\n",
    "#########\n",
    "pages_dir='%s/data/pages/'% (basedir)\n",
    "if not(os.path.exists(pages_dir)): os.mkdir(pages_dir)\n",
    "\n",
    "pages_data=load_pages(pagenames,pages_dir)\n",
    "talk_pages_data=load_pages(list(map(lambda x:''.join(['Talk:',x]),pagenames)),pages_dir)  \n",
    "\n",
    "print 'Number of pages load:',len(pages_data)\n",
    "print 'Number of talk pages load:',len(talk_pages_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Statistics computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>Pageid</th>\n",
       "      <th>Length</th>\n",
       "      <th>NS</th>\n",
       "      <th>Nb revisions</th>\n",
       "      <th>Nb revisions IP</th>\n",
       "      <th>Nb revisions bot</th>\n",
       "      <th>Nb revisions wiki</th>\n",
       "      <th>Nb editos</th>\n",
       "      <th>Nb editors IP</th>\n",
       "      <th>Nb editors Bot</th>\n",
       "      <th>Nb editors Wiki</th>\n",
       "      <th>Links</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>                        Digital geometry</td>\n",
       "      <td>   386413</td>\n",
       "      <td>  7211</td>\n",
       "      <td> 0</td>\n",
       "      <td> 116</td>\n",
       "      <td>  51</td>\n",
       "      <td> 11</td>\n",
       "      <td>  54</td>\n",
       "      <td>  63</td>\n",
       "      <td> 16</td>\n",
       "      <td>  7</td>\n",
       "      <td> 40</td>\n",
       "      <td>  46</td>\n",
       "      <td> 1052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>                      Synthetic geometry</td>\n",
       "      <td>   267484</td>\n",
       "      <td> 11870</td>\n",
       "      <td> 0</td>\n",
       "      <td> 129</td>\n",
       "      <td>  14</td>\n",
       "      <td> 11</td>\n",
       "      <td> 104</td>\n",
       "      <td>  60</td>\n",
       "      <td> 11</td>\n",
       "      <td>  5</td>\n",
       "      <td> 44</td>\n",
       "      <td>  98</td>\n",
       "      <td>  910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>                     Triangle inequality</td>\n",
       "      <td>    53941</td>\n",
       "      <td> 25011</td>\n",
       "      <td> 0</td>\n",
       "      <td> 395</td>\n",
       "      <td> 122</td>\n",
       "      <td> 28</td>\n",
       "      <td> 245</td>\n",
       "      <td> 199</td>\n",
       "      <td> 88</td>\n",
       "      <td> 12</td>\n",
       "      <td> 99</td>\n",
       "      <td>  87</td>\n",
       "      <td>  498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>                             Deltahedron</td>\n",
       "      <td>   493995</td>\n",
       "      <td> 13811</td>\n",
       "      <td> 0</td>\n",
       "      <td> 197</td>\n",
       "      <td>  18</td>\n",
       "      <td> 19</td>\n",
       "      <td> 160</td>\n",
       "      <td>  69</td>\n",
       "      <td> 13</td>\n",
       "      <td>  5</td>\n",
       "      <td> 51</td>\n",
       "      <td>  70</td>\n",
       "      <td> 1139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>                Isoperimetric inequality</td>\n",
       "      <td>   326182</td>\n",
       "      <td> 19249</td>\n",
       "      <td> 0</td>\n",
       "      <td> 176</td>\n",
       "      <td>  28</td>\n",
       "      <td> 27</td>\n",
       "      <td> 121</td>\n",
       "      <td>  94</td>\n",
       "      <td> 21</td>\n",
       "      <td> 12</td>\n",
       "      <td> 61</td>\n",
       "      <td> 105</td>\n",
       "      <td>  982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td> Matrix representation of conic sections</td>\n",
       "      <td>   189243</td>\n",
       "      <td>  7787</td>\n",
       "      <td> 0</td>\n",
       "      <td> 110</td>\n",
       "      <td>  31</td>\n",
       "      <td>  9</td>\n",
       "      <td>  70</td>\n",
       "      <td>  62</td>\n",
       "      <td> 16</td>\n",
       "      <td>  3</td>\n",
       "      <td> 43</td>\n",
       "      <td>  31</td>\n",
       "      <td>  773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>             Orthodiagonal quadrilateral</td>\n",
       "      <td> 30425383</td>\n",
       "      <td> 12496</td>\n",
       "      <td> 0</td>\n",
       "      <td>  71</td>\n",
       "      <td>   3</td>\n",
       "      <td>  5</td>\n",
       "      <td>  63</td>\n",
       "      <td>  16</td>\n",
       "      <td>  3</td>\n",
       "      <td>  3</td>\n",
       "      <td> 10</td>\n",
       "      <td>  57</td>\n",
       "      <td> 3648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>                 Invariant (mathematics)</td>\n",
       "      <td>  1126638</td>\n",
       "      <td> 11436</td>\n",
       "      <td> 0</td>\n",
       "      <td> 147</td>\n",
       "      <td>  25</td>\n",
       "      <td> 18</td>\n",
       "      <td> 104</td>\n",
       "      <td>  77</td>\n",
       "      <td> 20</td>\n",
       "      <td>  8</td>\n",
       "      <td> 49</td>\n",
       "      <td> 127</td>\n",
       "      <td> 1387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>                    Information geometry</td>\n",
       "      <td>   487312</td>\n",
       "      <td> 31534</td>\n",
       "      <td> 0</td>\n",
       "      <td> 205</td>\n",
       "      <td>  35</td>\n",
       "      <td>  7</td>\n",
       "      <td> 163</td>\n",
       "      <td>  78</td>\n",
       "      <td> 26</td>\n",
       "      <td>  4</td>\n",
       "      <td> 48</td>\n",
       "      <td>  95</td>\n",
       "      <td> 1136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>                              Zonohedron</td>\n",
       "      <td>   669402</td>\n",
       "      <td> 14056</td>\n",
       "      <td> 0</td>\n",
       "      <td> 126</td>\n",
       "      <td>   9</td>\n",
       "      <td>  9</td>\n",
       "      <td> 108</td>\n",
       "      <td>  48</td>\n",
       "      <td>  7</td>\n",
       "      <td>  4</td>\n",
       "      <td> 37</td>\n",
       "      <td>  91</td>\n",
       "      <td> 1222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     title    Pageid  Length  NS  \\\n",
       "0                         Digital geometry    386413    7211   0   \n",
       "1                       Synthetic geometry    267484   11870   0   \n",
       "2                      Triangle inequality     53941   25011   0   \n",
       "3                              Deltahedron    493995   13811   0   \n",
       "4                 Isoperimetric inequality    326182   19249   0   \n",
       "5  Matrix representation of conic sections    189243    7787   0   \n",
       "6              Orthodiagonal quadrilateral  30425383   12496   0   \n",
       "7                  Invariant (mathematics)   1126638   11436   0   \n",
       "8                     Information geometry    487312   31534   0   \n",
       "9                               Zonohedron    669402   14056   0   \n",
       "\n",
       "   Nb revisions  Nb revisions IP  Nb revisions bot  Nb revisions wiki  \\\n",
       "0           116               51                11                 54   \n",
       "1           129               14                11                104   \n",
       "2           395              122                28                245   \n",
       "3           197               18                19                160   \n",
       "4           176               28                27                121   \n",
       "5           110               31                 9                 70   \n",
       "6            71                3                 5                 63   \n",
       "7           147               25                18                104   \n",
       "8           205               35                 7                163   \n",
       "9           126                9                 9                108   \n",
       "\n",
       "   Nb editos  Nb editors IP  Nb editors Bot  Nb editors Wiki  Links  Date  \n",
       "0         63             16               7               40     46  1052  \n",
       "1         60             11               5               44     98   910  \n",
       "2        199             88              12               99     87   498  \n",
       "3         69             13               5               51     70  1139  \n",
       "4         94             21              12               61    105   982  \n",
       "5         62             16               3               43     31   773  \n",
       "6         16              3               3               10     57  3648  \n",
       "7         77             20               8               49    127  1387  \n",
       "8         78             26               4               48     95  1136  \n",
       "9         48              7               4               37     91  1222  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stat_computation(pages_data):\n",
    "    df = pd.DataFrame(pages_data.keys(),columns=['title'])\n",
    "    #pageid\n",
    "    data={k:v['pageid'] for k,v in pages_data.items()}\n",
    "    df=df.merge(pd.DataFrame(data.items(),columns=['title','Pageid']))\n",
    "    #length\n",
    "    data={k:v['length'] for k,v in pages_data.items()}\n",
    "    df=df.merge(pd.DataFrame(data.items(),columns=['title','Length']))\n",
    "    #ns\n",
    "    data={k:v['ns'] for k,v in pages_data.items()}\n",
    "    df=df.merge(pd.DataFrame(data.items(),columns=['title','NS']))\n",
    "    #nombre de revisions\n",
    "    data={k:len(v['revisions']) for k,v in pages_data.items()}\n",
    "    df=df.merge(pd.DataFrame(data.items(),columns=['title','Nb revisions']))\n",
    "    #nombre de revisions by IP\n",
    "    data={k:len( list(filter(lambda x: ('userid' in x) and (x['userid']==0),v['revisions'])) )  for k,v in pages_data.items()}\n",
    "    df=df.merge(pd.DataFrame(data.items(),columns=['title','Nb revisions IP']))\n",
    "    #nombre de revisions by Bot\n",
    "    data={k:len( list(filter(lambda x: ('userid' in x) and (x['userid']!=0) and ('bot' in x['user'].lower()),v['revisions'])) )  for k,v in pages_data.items()}\n",
    "    df=df.merge(pd.DataFrame(data.items(),columns=['title','Nb revisions bot']))\n",
    "    #nombre de revisions by Alive Registered Members\n",
    "    data={k:len( list(filter(lambda x: ('userid' in x) and (x['userid']!=0) and ('bot' not in x['user'].lower()),v['revisions'])) )  for k,v in pages_data.items()}\n",
    "    df=df.merge(pd.DataFrame(data.items(),columns=['title','Nb revisions wiki']))\n",
    "    #nombre de contributeurs\n",
    "    data={k:len(set(list(map(lambda x: x['user'],filter(lambda x:'user' in x,v['revisions'])))))  for k,v in pages_data.items()}\n",
    "    df=df.merge(pd.DataFrame(data.items(),columns=['title','Nb editos']))\n",
    "    #nombre de contributeurs IP\n",
    "    data={k:len(set(list(map(lambda x: x['user'],filter(lambda x:('userid' in x) and (x['userid']==0),v['revisions'])))))  for k,v in pages_data.items()}\n",
    "    df=df.merge(pd.DataFrame(data.items(),columns=['title','Nb editors IP']))\n",
    "    #nombre de contributeurs Bot\n",
    "    data={k:len(set(list(map(lambda x: x['user'],filter(lambda x:('userid' in x) and (x['userid']!=0) and ('bot' in x['user']),v['revisions'])))))  for k,v in pages_data.items()}\n",
    "    df=df.merge(pd.DataFrame(data.items(),columns=['title','Nb editors Bot']))\n",
    "    #nombre de contributeurs by Alive Registered Members\n",
    "    data={k:len(set(list(map(lambda x: x['user'],filter(lambda x:('userid' in x) and (x['userid']!=0) and ('bot' not in x['user']),v['revisions'])))))  for k,v in pages_data.items()}\n",
    "    df=df.merge(pd.DataFrame(data.items(),columns=['title','Nb editors Wiki']))\n",
    "    #nombre de revisions\n",
    "    data={k:len(v['links']) for k,v in pages_data.items()}\n",
    "    df=df.merge(pd.DataFrame(data.items(),columns=['title','Links']))\n",
    "    #date of the first contibutions (in number of days after the start of the wikipedia project)\n",
    "    import datetime\n",
    "    def numberOfDaysAfter(date):\n",
    "        return( (datetime.datetime.strptime(date,\"%Y-%m-%dT%H:%M:%SZ\")-datetime.datetime.strptime(\"2001-01-15T00:00:00Z\",\"%Y-%m-%dT%H:%M:%SZ\")).days)\n",
    "    data={k:min(map(numberOfDaysAfter,map(lambda x: x['timestamp'],v['revisions'])))  for k,v in pages_data.items()}\n",
    "    df=df.merge(pd.DataFrame(data.items(),columns=['title','Date']))\n",
    "    return(df)\n",
    "\n",
    "########\n",
    "stat_dir = \"%s/stats/\" % basedir\n",
    "if not(os.path.exists(stat_dir)): os.mkdir(stat_dir)\n",
    "basic_stats_file='basic_stats.csv'\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "if (os.path.exists(\"%s/%s\" % (stat_dir,basic_stats_file))):\n",
    "    df = df.from_csv(\"%s/%s\" % (stat_dir,basic_stats_file),encoding=\"utf-8\")\n",
    "else:\n",
    "    df = stat_computation(pages_data)\n",
    "    df.to_csv(\"%s/%s\" % (stat_dir,basic_stats_file),encoding=\"utf-8\")\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistique on content of the last revision\n",
    "\n",
    "## Gathering last revision content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of revisions of page load: 303\n"
     ]
    }
   ],
   "source": [
    "def load_content_last_revision(listofpages,data_dir):\n",
    "    last_revision_data = {}\n",
    "    for page in listofpages:\n",
    "        if (os.path.exists('%s/%s.html'%(data_dir,page))):\n",
    "            last_revision_data[page] = ''.join(codecs.open('%s/%s.html'%(data_dir,page),\"r\", \"utf-8-sig\").readlines())\n",
    "        else:\n",
    "            data = {}\n",
    "            p = Page()\n",
    "            req = p.fetch_info(page)['query']['pages']\n",
    "            pageid = list(req)[0]  \n",
    "            if pageid!='-1':\n",
    "                last_revision_data[page] = p.get_current()[0]\n",
    "                f = open('%s/%s.html'% (data_dir,page),'w')\n",
    "                f.write(last_revision_data[page].encode('utf-8'))\n",
    "                f.close()\n",
    "                \n",
    "    return(last_revision_data)\n",
    "\n",
    "revision_dir = '%s/data/revisions/' %basedir\n",
    "if not(os.path.exists(revision_dir)): os.mkdir(revision_dir)\n",
    "\n",
    "last_revision_data = load_content_last_revision(pagenames,revision_dir)\n",
    "## store the content of the last revisions also in pages_data\n",
    "for k in last_revision_data:\n",
    "    pages_data[k]['lastrevision']=last_revision_data[k]\n",
    "\n",
    "print 'Number of revisions of page load:',len(pages_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computation of statistics on content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average_word_length</th>\n",
       "      <th>nbwords</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 3.333072</td>\n",
       "      <td>  5529</td>\n",
       "      <td>                        Digital geometry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 4.075610</td>\n",
       "      <td> 10405</td>\n",
       "      <td>                      Synthetic geometry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 2.712475</td>\n",
       "      <td> 16398</td>\n",
       "      <td>                     Triangle inequality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 1.466334</td>\n",
       "      <td>  6923</td>\n",
       "      <td>                             Deltahedron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 3.382720</td>\n",
       "      <td> 14406</td>\n",
       "      <td>                Isoperimetric inequality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td> 1.929956</td>\n",
       "      <td>  4685</td>\n",
       "      <td> Matrix representation of conic sections</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td> 3.552224</td>\n",
       "      <td>  9109</td>\n",
       "      <td>             Orthodiagonal quadrilateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td> 3.444048</td>\n",
       "      <td>  9968</td>\n",
       "      <td>                 Invariant (mathematics)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td> 2.254628</td>\n",
       "      <td> 17230</td>\n",
       "      <td>                    Information geometry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td> 2.771525</td>\n",
       "      <td>  8980</td>\n",
       "      <td>                              Zonohedron</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   average_word_length  nbwords                                    title\n",
       "0             3.333072     5529                         Digital geometry\n",
       "1             4.075610    10405                       Synthetic geometry\n",
       "2             2.712475    16398                      Triangle inequality\n",
       "3             1.466334     6923                              Deltahedron\n",
       "4             3.382720    14406                 Isoperimetric inequality\n",
       "5             1.929956     4685  Matrix representation of conic sections\n",
       "6             3.552224     9109              Orthodiagonal quadrilateral\n",
       "7             3.444048     9968                  Invariant (mathematics)\n",
       "8             2.254628    17230                     Information geometry\n",
       "9             2.771525     8980                               Zonohedron"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def basic_word_analysis(pages_content):\n",
    "    data =[]\n",
    "    for k,content in pages_content.items():\n",
    "        p={}\n",
    "        p['title']=k\n",
    "        text = BeautifulSoup(content).text\n",
    "        p['nbwords'] = len(text)\n",
    "        words = len(content.split(\" \"))\n",
    "        p['average_word_length'] = float(p['nbwords'] - words)/float(words)   \n",
    "        data.append(p)\n",
    "    res = pd.DataFrame(data)\n",
    "    if len(pages_content)!=0: res.set_index('title')\n",
    "    return res\n",
    "\n",
    "########\n",
    "if not(os.path.exists(stat_dir)): os.mkdir(stat_dir)\n",
    "basic_stats_file='words_stats.csv'\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "if (os.path.exists(\"%s/%s\" % (stat_dir,basic_stats_file))):\n",
    "    df = df.from_csv(\"%s/%s\" % (stat_dir,basic_stats_file),encoding=\"utf-8\")\n",
    "else:\n",
    "    df = basic_word_analysis(last_revision_data)\n",
    "    df.to_csv(\"%s/%s\" % (stat_dir,basic_stats_file),encoding=\"utf-8\")\n",
    "\n",
    "df.head(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Graph Construction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph of links computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph of links:\n",
      "  number of nodes: 303\n",
      "  number of edges: 2975\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from networkx.algorithms import bipartite \n",
    "import networkx as nx\n",
    "\n",
    "# Add an occurence of the title in the content of the page\n",
    "def build_links_graph(data):\n",
    "    global last_revision_data\n",
    "    links_graph = nx.Graph()\n",
    "    for page in data: links_graph.add_node(page)\n",
    "    for page in data:\n",
    "        links = data[page]['links']\n",
    "        intradomain = set(links) & set(data.keys())\n",
    "        gruyere = last_revision_data[page]\n",
    "        linkssort = sorted(intradomain, key=lambda k: -len(k))\n",
    "        for l in linkssort:\n",
    "            occurences_link = len(filter(lambda x:x==l,links))\n",
    "            occurences_named_entity = unicode(gruyere).count(unicode(k))\n",
    "            gruyere = gruyere.replace(k, \"\")\n",
    "            links_graph.add_edge(page,l,attr_dict={\"link occurence\": occurences_link, \"term occurence\": occurences_named_entity})\n",
    "    return(links_graph)\n",
    "\n",
    "#####\n",
    "graph_dir = '%s/graph/' % (basedir)\n",
    "if not(os.path.exists(graph_dir)): os.mkdir(graph_dir)\n",
    "\n",
    "links_graph = nx.Graph()\n",
    "if (os.path.exists(\"%s/links-graph.gexf\" % (graph_dir))):\n",
    "    links_graph = nx.read_gexf(\"%s/links-graph.gexf\" % (graph_dir))\n",
    "else:\n",
    "    links_graph = build_links_graph(pages_data)\n",
    "    nx.write_gexf(links_graph, \"%s/links-graph.gexf\" % (graph_dir))\n",
    "\n",
    "print 'Graph of links:'\n",
    "print '  number of nodes:',len(links_graph.nodes())\n",
    "print '  number of edges:',len(links_graph.edges())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## bipartite page-editors graph computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bipartite graph page/editors\n",
      "  number of nodes: 16206\n",
      "  number of edges: 40044\n"
     ]
    }
   ],
   "source": [
    "def build_bipartite(data):\n",
    "    pages_editors_graph = nx.Graph()\n",
    "    editors_all = {}\n",
    "    for p in data.keys():\n",
    "        editors = Counter(list(map(lambda x:x['user'],filter(lambda x: ('user' in x) and (x['userid']!=0),data[p]['revisions']))))\n",
    "        pages_editors_graph.add_node(''.join(['p:',p]), type='page')\n",
    "        for e in editors:\n",
    "            if e not in editors_all: \n",
    "                pages_editors_graph.add_node(''.join(['u:',e]), type=\"user\")\n",
    "                editors_all[e]=editors[e]\n",
    "            else:\n",
    "                editors_all[e]+=editors[e]\n",
    "            pages_editors_graph.add_edge(''.join(['u:',e]), ''.join(['p:',p]), attr_dict={'revisions':editors[e]})\n",
    "    #add number of revision on editor node\n",
    "    for e in editors_all:\n",
    "         pages_editors_graph.node[''.join(['u:',e])][\"revisions\"]=editors_all[e]\n",
    "    return(pages_editors_graph)\n",
    "        \n",
    "pages_editors_graph = nx.Graph()\n",
    "if (os.path.exists(\"%s/pages-editors-graph.gexf\" % (stat_dir))):\n",
    "    pages_editors_graph = nx.read_gexf(\"%s/pages-editors-graph.gexf\" % (graph_dir))\n",
    "else:\n",
    "    pages_editors_graph = build_bipartite(pages_data)\n",
    "    nx.write_gexf(pages_editors_graph, \"%s/pages-editors-graph.gexf\" % (graph_dir)) \n",
    "\n",
    "print 'Bipartite graph page/editors'\n",
    "print '  number of nodes:',len(pages_editors_graph.nodes())\n",
    "print '  number of edges:',len(pages_editors_graph.edges())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projection graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projection graph on pages\n",
      "  number of nodes: 303\n",
      "  number of edges: 44759\n"
     ]
    }
   ],
   "source": [
    "from networkx.algorithms import bipartite \n",
    "\n",
    "def projected_graph(G,select, weight=\"weight\"):\n",
    "    selected = map(lambda x:x[0],filter(lambda x:x[1]['type']==select,G.nodes(data=True)))\n",
    "    res=bipartite.projected_graph(G, selected)\n",
    "    for u in res.nodes():\n",
    "        for v in res[u].keys():\n",
    "            w = len(set(G[u]) & set(G[v]))\n",
    "            res[u][v][weight] = w\n",
    "    return(res)\n",
    "\n",
    "projected_graph_page = nx.Graph()\n",
    "if (os.path.exists(\"%s/projected_graph_page.gexf\" % (graph_dir))):\n",
    "    projected_graph_page = nx.read_gexf(\"%s/projected_graph_page.gexf\" % (graph_dir))\n",
    "else:\n",
    "    projected_graph_page = projected_graph(pages_editors_graph,'page','coeditors')\n",
    "    nx.write_gexf(projected_graph_page, \"%s/projected_graph_page.gexf\" % (graph_dir))   \n",
    "\n",
    "print 'Projection graph on pages'\n",
    "print '  number of nodes:',len(projected_graph_page.nodes())\n",
    "print '  number of edges:',len(projected_graph_page.edges())\n",
    "\n",
    "#projected_graph_user = nx.Graph()\n",
    "#if (os.path.exists(\"%s/projected_graph_user.gexf\" % (graph_dir))):\n",
    "#    projected_graph_user = nx.read_gexf(\"%s/projected_graph_user.gexf\" % (graph_dir))\n",
    "#else:\n",
    "#    projected_graph_user = projected_graph(pages_editors_graph,'user')\n",
    "#    nx.write_gexf(projected_graph_user, \"%s/projected_graph_user.gexf\" % (graph_dir))   \n",
    "\n",
    "#print 'Projection graph on users'\n",
    "#print '  number of nodes:',len(projected_graph_user.nodes())\n",
    "#print '  number of edges:',len(projected_graph_user.edges())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics on graph    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NetworkXError",
     "evalue": "Graph not connected.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNetworkXError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-816ecdde481b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[0mdf_pro_graph_page_node\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf_pro_graph_page_pair\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_graph_statistics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprojected_graph_page\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'projected_graph_page'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m \u001b[0mdf_links_graph_node\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf_links_graph_pair\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_graph_statistics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinks_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'links_graph'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-816ecdde481b>\u001b[0m in \u001b[0;36mcompute_graph_statistics\u001b[1;34m(graph, prefix_file, weightNode, weightEdge)\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mdata_frame_node\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_frame_node\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0mdata_frame_node\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_graph_statistics_on_nodes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweightNode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m         \u001b[0mdata_frame_node\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-816ecdde481b>\u001b[0m in \u001b[0;36mcompute_graph_statistics_on_nodes\u001b[1;34m(graph, weight)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mcloseness\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcloseness_centrality\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mbetweenness\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbetweenness_centrality\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mcurrent_flow_closeness\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_flow_closeness_centrality\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mcurrent_flow_betweenness\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_flow_betweenness_centrality\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mpagerank\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpagerank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/networkx/algorithms/centrality/current_flow_closeness.pyc\u001b[0m in \u001b[0;36mcurrent_flow_closeness_centrality\u001b[1;34m(G, weight, dtype, solver)\u001b[0m\n\u001b[0;32m     71\u001b[0m             \"current_flow_closeness_centrality() not defined for digraphs.\")\n\u001b[0;32m     72\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_connected\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNetworkXError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Graph not connected.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     solvername = {\"full\": FullInverseLaplacian,\n\u001b[0;32m     75\u001b[0m                   \u001b[1;34m\"lu\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mSuperLUInverseLaplacian\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNetworkXError\u001b[0m: Graph not connected."
     ]
    }
   ],
   "source": [
    "def compute_graph_statistics_on_nodes(graph,weight=None):\n",
    "    network_df = pd.DataFrame(index=graph.nodes())\n",
    "    \n",
    "    centrality = nx.degree_centrality(graph)\n",
    "    closeness = nx.closeness_centrality(graph)\n",
    "    betweenness = nx.betweenness_centrality(graph, weight=weight)\n",
    "    current_flow_closeness = nx.current_flow_closeness_centrality(graph, weight=weight)\n",
    "    current_flow_betweenness = nx.current_flow_betweenness_centrality(graph, weight=weight)\n",
    "    pagerank = nx.pagerank(graph,weight=weight)\n",
    "    eigenvector = nx.eigenvector_centrality_numpy(graph, weight=weight)\n",
    "\n",
    "    for index in network_df.index:\n",
    "        network_df.ix[index,\"degree\"] = len(graph[index])\n",
    "        network_df.ix[index,\"pagerank\"] = pagerank[index]\n",
    "        network_df.ix[index,\"centrality\"] = centrality[index]\n",
    "        network_df.ix[index,\"closeness\"] = closeness[index]\n",
    "        network_df.ix[index,\"betweenness\"] = betweenness[index]\n",
    "        network_df.ix[index,\"current flow closeness\"] = current_flow_closeness[index]\n",
    "        network_df.ix[index,\"current flow betweenness\"] = current_flow_betweenness[index]\n",
    "        network_df.ix[index,\"eigenvector\"] = eigenvector[index]\n",
    "\n",
    "    return network_df\n",
    " \n",
    "def compute_graph_statistics_on_pair_of_nodes(graph,weight=None):\n",
    "    network_df = pd.DataFrame(index=[(x,y) for x in graph.nodes() for y in graph.nodes()])\n",
    "    communicability = nx.communicability(graph)\n",
    "    shortest_path = nx.shortest_path(graph,weight=weight)\n",
    "    for k in graph.nodes()[0:5]:\n",
    "        for v in graph.nodes()[0:5]:\n",
    "            network_df.ix[(k,v),\"communicability\"] = communicability[k][v]\n",
    "            network_df.ix[(k,v),\"shortest_path\"] = len(shortest_path[k][v])\n",
    "    return(network_df)\n",
    "\n",
    "def compute_graph_statistics(graph,prefix_file,weightNode=None,weightEdge=None):\n",
    "    data_frame_node = pd.DataFrame()\n",
    "    filename = \"%s/%s-nodes-stats.csv\" % (stat_dir,prefix_file)\n",
    "    if (os.path.exists(filename)):\n",
    "        data_frame_node = data_frame_node.from_csv(filename)\n",
    "    else:\n",
    "        data_frame_node = compute_graph_statistics_on_nodes(graph,weightNode)\n",
    "        data_frame_node.to_csv(filename,encoding=\"utf-8\")\n",
    "    \n",
    "    data_frame_pair = pd.DataFrame()\n",
    "    filename = \"%s/%s-pair-stats.csv\" % (stat_dir,prefix_file)\n",
    "    if (os.path.exists(filename)):\n",
    "        data_frame_pair = data_frame_pair.from_csv(filename)\n",
    "    else:\n",
    "        data_frame_pair = compute_graph_statistics_on_pair_of_nodes(graph,weightEdge)\n",
    "        data_frame_pair.to_csv(filename,encoding=\"utf-8\")\n",
    "    \n",
    "    return(data_frame_node,data_frame_pair)\n",
    "\n",
    "df_pro_graph_page_node,df_pro_graph_page_pair = compute_graph_statistics(projected_graph_page,'projected_graph_page')\n",
    "df_links_graph_node,df_links_graph_pair = compute_graph_statistics(links_graph,'links_graph')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Intersection graph\n",
    "\n",
    "Build a graph using links graph et projection: a edge between two page not far away in links graph et adjacent in projection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def intersection_graph():\n",
    "    global projected_graph_page, links_graph\n",
    "    global df_links_graph_pair\n",
    "    \n",
    "    res = nx.Graph()\n",
    "    for p in links_graph.nodes():\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pageview and revisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reading map based on a reduced graph of co-edited pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
